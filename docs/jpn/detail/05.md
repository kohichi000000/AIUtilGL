# ⑤セキュリティの原則

## a-セキュリティ対策の実施

### 解説

AIサービスプロバイダ及びビジネス利用者は、AIのセキュリティに留意し、
AIシステムの機密性・安全性・可用性を確保するため、
その時点での技術水準に照らして合理的な対策を講ずることが期待される。

また、**セキュリティが侵害された場合に講ずるべき措置**について、
当該AIの用途や特性、侵害の影響の大きさ等を踏まえ、
あらかじめ整理しておくことが期待される。

#### セキュリティ侵害時の措置の例

* 初動措置（当該AIを含むシステムの急用度等の文脈に応じ、必要な手順にて実施）
	* 当該システムのロールバック`1`、代替システムの利用などによる復旧
	* システムの停止（キルスイッチ）：可能な場合
	* ネットワークからの遮断：可能な場合
	* セキュリティ侵害の内容確認
	* 関係者への報告
* 補償・賠償等（補償・賠償等を円滑に行うための保険の利用）
* 重大な損害が生じた場合等は、第三者機関の設置とその機関による原因調査・分析・提言など

----

`1`) 障害が起こった際等に、直前の（保存した）状態まで戻ること。 

----

### 参考

消費者的利用者は、（消費者的利用者側で）セキュリティ対策を実施することが想定されている場合には、開発者及び
AIサービスプロバイダからの情報提供を踏まえ、AIのセキュリティに留意し、必要な対策を講ずることが望ましい。

****************

* [トップページ](../../)

****************


## b-セキュリティ対策のためのサービス提供等

### 解説

AIサービスプロバイダは、自ら提供するAIサービスについて、
最終利用者にセキュリティ対策のためのサービスを提供するとともに、
過去のアクシデントやインシデント情報の共有を図ることが期待される。

また、AIサービスプロバイダ及びビジネス利用者はセキュリティが侵害された場合の措置について、
消費者的利用者に対し必要な情報提供を行うことが期待される。

### 参考

消費者的利用者は、セキュリティが侵害された場合に講ずるべき措置について、開発者及び
AIサービスプロバイダから情報提供があった場合には、利用にあたり留意することが望ましい。

また、AIを利用するに当たり、セキュリティ上の疑問を感じた場合は、
開発者、AIサービスプロバイダ、データ提供者等にその旨を報告することが望ましい。

****************

* [トップページ](../../)

****************

＜参考＞


## c-AIの学習モデルに対するセキュリティ脆弱性への留意

### 解説
AIサービスプロバイダ、ビジネス利用者及びデータ提供者は、
学習モデルの生成及びその管理において、セキュリティに脆弱性が存在する**リスク**に留意することが期待される。

また、消費者的利用者に対し、そのようなリスクが存在することを予め周知することが期待される。

#### リスクの例
* 学習が不十分であること等の結果、学習モデルが正確に判断することができるデータに、人間には判別できない程度の微少な変動を加え、そのデータをインプットすること等により、作為的に当該学習モデルの判断を誤らせることができるリスク（例：Adversarial example攻撃）
* （教師あり学習において）学習において不正確なラベリング等がなされたデータを混在させることで、誤った学習が行われるリスク
* 学習モデルが容易に複製できるリスク
* 学習モデルから学習に用いられたデータをリバースエンジニアリングできるリスク

### 参考

消費者的利用者は、開発者、AIサービスプロバイダ及びデータ提供者からの情報を踏まえ、
学習モデルの生成及びその管理において、セキュリティに脆弱性が存在するリスクに留意することが望ましい。

また、AIを利用するに当たり、セキュリティ上の疑問を感じた場合は、
開発者、AIサービスプロバイダ、データ提供者等にその旨を報告することが望ましい。

****************
  
* [トップページ](../../)

****************

