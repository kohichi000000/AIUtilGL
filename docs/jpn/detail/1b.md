# ①ーイ） 人間の判断の介在

AIによりなされた判断について、必要かつ可能な場合には、その判断を用いるか否か、あるいは、
どのように用いるか等に関し、人間の判断を介在させることが期待される。
その場合、人間の判断の介在の要否については、例えば以下の基準の下、
利用分野、用途等に応じて検討されることが期待される。

#### [人間の判断の介在の要否について、基準として考えられる観点（例）]
* AIの判断に影響を受ける最終利用者等の権利・利益の性質及び意向（例えば、人生を左右しかねない意思決定に係わるAIの利用時等）
* AIの判断の信頼性の程度（人間による判断の信頼性との優劣）
* 人間の判断に必要な時間的猶予
* 利用者に期待される能力
* 判断対象の要保護性（例えば、AIによる大量申請への対応等）

また、AIの判断に対し、人間が最終判断をすることが適当とされている場合に、
人間がAIと異なる判断をすることが期待できなくなることも想定される。
こうした場合に人間が行うべき判断についてその項目、手段などを明確化することにより、人間の判断の実効性を確保することが考えられる。

####［実効性を確保するための手段の例]
* 説明可能性を有するAIから得られる説明を前提として、最終判断に必要となるチェック項目の作成
* AIの判断の適正性を確認するためのチェック項目の作成（能動的な判断の実施（他のAIを利用したダブルチェック、
AIへの入力を摂動させることよるAI動作の確認など））

また、アクチュエータ等を通じて稼働するAIの利活用において、一定の条件に該当することにより
人間による稼働に移行することが予定されている場合、
移行前、移行中、移行後等の各状態に伴い、予め責任の所在が明確になっている必要がある。

また、前述の移行条件、移行方法等を利用者に事前に告知し、必要な訓練などを前もって実施するなど、
人間による稼働に移行した場合に問題が起こらないよう、注意喚起をしておくことが期待される。 

****

## 消費者的利用者
