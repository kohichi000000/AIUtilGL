# ①ーイ） 人間の判断の介在

ＡＩによりなされた判断について、必要かつ可能な場合には、その判断を用いるか否か、あるいは、どのように用いるか等に関し、人間の判断を介在させることが期待される。その場合、人間の判断の介在の要否については、例えば以下の基準の下、利用分野、用途等に応じて検討されることが期待される。

#### [人間の判断の介在の要否について、基準として考えられる観点（例）]
* ＡＩの判断に影響を受ける最終利用者等の権利・利益の性質及び意向（例えば、人生を左右しかねない意思決定に係わるＡＩの利用時等）
* ＡＩの判断の信頼性の程度（人間による判断の信頼性との優劣）
* 人間の判断に必要な時間的猶予
* 利用者に期待される能力
* 判断対象の要保護性（例えば、ＡＩによる大量申請への対応等）

また、ＡＩの判断に対し、人間が最終判断をすることが適当とされている場合に、人間がＡＩと異なる判断をすることが期待できなくなることも想定される。
こうした場合に人間が行うべき判断についてその項目、手段などを明確化することにより、人間の判断の実効性を確保することが考えられる。

####［実効性を確保するための手段の例]
* 説明可能性を有するＡＩから得られる説明を前提として、最終判断に必要となるチェック項目の作成
* ＡＩの判断の適正性を確認するためのチェック項目の作成（能動的な判断の実施（他のＡＩを利用したダブルチェック、ＡＩへの入力を摂動させることよるＡＩ動作の確認など））

また、アクチュエータ等を通じて稼働するＡＩの利活用において、一定の条件に該当することにより人間による稼働に移行することが予定されている場合、
移行前、移行中、移行後等の各状態に伴い、予め責任の所在が明確になっている必要がある。また、前述の移行条件、移行方法等を利用者に事前に告知し、必要な訓練などを前もって実施するなど、人間による稼働に移行した場合に問題が起こらないよう、注意喚起をしておくことが期待される。 (