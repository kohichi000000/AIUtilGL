# ①適正利用の原則

<h2 id="a01a">ア-適正な範囲・方法での利用</h2>

### AIサービスプロバイダ、ビジネス利用者等

AIサービスプロバイダ及びビジネス利用者は、AIを消費者的利用者等に提供し、
又は、自ら運用するに当たり、開発者等からの情報提供や説明を踏まえ、
以下に関する情報を適時適切に提供することが期待される。

#### 提供すべき情報
* 提供するAIの利用に関する適正な用途・方法。 
* AIの性質、利用の態様等に応じた、便益及びリスクに関する情報。
* 提供するAIの利活用の範囲・方法に関する定期的な確認方法（特に、AIが自律的に更新される場合の観測、確認方法）、
及び確認の重要性、頻度、未確認によるリスク等。
* 利活用の過程を通じて、AIの機能を向上させ、リスクを抑制するため、AIソフトのアップデート及びAIの点検・修理等を行うための情報。

#### 情報を提供すべきタイミング
* AIの利用前に当該情報を提供できることが望ましい。
* 事前に当該情報を提供できない場合に備え、AIの性質、利用の態様等に基づき考えられるリスクに応じ、
消費者的利用者等からのフィードバックに対応する体制が整備されていることが望ましい。 

また、利活用の過程を通じて、AIの機能を向上させ、リスクを抑制するため、AIソフトのアップデート及び
AIの点検・修理等を提供することが期待される。特に、アップデートのための機能を提供する際に、
他のAIとの関係でリスク`1`が想定される場合は、当該リスク情報を提示した上で提供することが望ましい。

また、提供されるAIの性質、利用の態様等によっては、提供対象となる利用者が当該AIを提供するにふさわしい者
であるか（信頼性）について事前に考慮することが期待される場合も想定される。

----

`1`)アップデートを適用するAIの動作が周辺AIに影響を及ぼす場合等に留意が必要となる。
例えば、家庭内の家電に含まれるAIソフトの動作がアップデートにより変わった場合、
全体を統括する家庭内執事のようなロボットや周辺のAIを含む家電がアップデートの内容を知らないと、
（家電同士、および家電とロボットの）相互の判断に齟齬が生じる場合がある
（[「報告書2018」別紙３](http://www.soumu.go.jp/main_content/000564152.pdf)
「ＡＩが想定外の動作を行うなどのおそれ」の事例）。

____


### 消費者的利用者

消費者的利用者は、開発者、AIサービスプロバイダ、ビジネス利用者等からの情報提供や説明を踏まえ、社会的文脈や状
況にも配慮して、AIを適正な範囲・方法で利用することが期待される。具体的には以下に留意することが期待される。

#### 実施が期待される内容

##### 利用前
* AIの性質、利用の態様等に応じて、便益及びリスクを認識し、適正な用途を理解するとともに、
必要な知識・技能を習得すること等。

##### 利用中
* 自らのAIの利活用が適正な範囲・方法で行われているか定期的に確認すること。
* 利活用の過程を通じて、AIの機能を向上させ、リスクを抑制するため、AIソフトのアップデート及びAIの点検・修理等
を行うよう努めること。ただし、他のAIとの関係でのリスクが存在しうること1を理解した上で、アップデートを行うこと。
* 何らかの問題が発生した場合、問題が起こる予兆があった場合、もしくは、問題に対するフィードバッグを要求された場合、
開発者及びサービスプロバイダ等に対し、当該情報をフィードバックすること。


****************

****************


## イ-人間の判断の介在

### AIサービスプロバイダ、ビジネス利用者等

AIによりなされた判断について、必要かつ可能な場合には、その判断を用いるか否か、あるいは、
どのように用いるか等に関し、人間の判断を介在させることが期待される。
その場合、人間の判断の介在の要否については、例えば以下の基準の下、
利用分野、用途等に応じて検討されることが期待される。

#### ［人間の判断の介在の要否について、基準として考えられる観点（例）］
* AIの判断に影響を受ける最終利用者等の権利・利益の性質及び意向（例えば、人生を左右しかねない意思決定に係わるAIの利用時等）
* AIの判断の信頼性の程度（人間による判断の信頼性との優劣）
* 人間の判断に必要な時間的猶予
* 利用者に期待される能力
* 判断対象の要保護性（例えば、AIによる大量申請への対応等）

また、AIの判断に対し、人間が最終判断をすることが適当とされている場合に、
人間がAIと異なる判断をすることが期待できなくなることも想定される。
こうした場合に人間が行うべき判断についてその項目、手段などを明確化することにより、人間の判断の実効性を確保することが考えられる。

#### ［実効性を確保するための手段の例］
* 説明可能性を有するAIから得られる説明を前提として、最終判断に必要となるチェック項目の作成
* AIの判断の適正性を確認するためのチェック項目の作成（能動的な判断の実施（他のAIを利用したダブルチェック、
AIへの入力を摂動させることよるAI動作の確認など））

また、アクチュエータ等を通じて稼働するAIの利活用において、一定の条件に該当することにより
人間による稼働に移行することが予定されている場合、
移行前、移行中、移行後等の各状態に伴い、予め責任の所在が明確になっている必要がある。

また、前述の移行条件、移行方法等を利用者に事前に告知し、必要な訓練などを前もって実施するなど、
人間による稼働に移行した場合に問題が起こらないよう、注意喚起をしておくことが期待される。 

____

### 消費者的利用者

消費者的利用者は、AIの判断に対し、人間が最終判断をすることが適当とされている場合に、適切に判断ができるよう
能力を習得しておくことが期待される。加えて、こうした場合に人間が行うべき判断について開発者、AIサービスプロバイダ、ビ
ジネス利用者等により人間が行うべき判断についての項目、手段などが整理されている場合は、当該情報を入手し、これに
基づき対応することが期待される。

また、アクチュエータ等を通じて稼働するAIの利活用において、一定の条件に該当することにより人間による稼働に移行
することが予定されている場合、移行前、移行中、移行後等の各状態に伴う責任の所在を予め認識しておく必要がある。
また、前述の移行条件、移行方法等についての説明をサービスプロバイダ等から受け、必要な訓練などを受けておくことが期
待される。

****************

****************


## ウ-関係者間の協力

### AIサービスプロバイダ・ビジネス利用者等

AIサービスプロバイダ、ビジネス利用者及びデータ提供者は、AIを提供または利用するに
当たり、AIの利活用により生じ得る又は生じた事故、セキュリティ侵害、プライバシー侵害等に
よる被害の性質・態様等に応じて、関係者と協力して予防措置及び事後対応（情報共有、
停止・復旧、原因解明、再発防止措置等）に取り組むことが期待される。
また、具体的には、例えば以下に記載の内容等に留意することが期待される。

#### [関係者間で協力して行う予防措置（例）]
* [①適正利用の原則（本原則）論点ア：適正な範囲・方法での利用](#a01a)（適正な範囲・方法による利用のための情報の相互提供等）
* ④安全の原則（AIがアクチュエータ等を通じて人の生命・身体・財産に危害を及ぼした場合に講ずるべき措置等）
* ⑤セキュリティの原則（セキュリティが侵害された場合に講ずるべき措置等）
* ⑥プライバシーの原則（他者のプライバシーを侵害した場合に講ずるべき措置等）等

____

### 消費者的利用者

消費者的利用者は、AIを利用するに当たり、AIの利活用により生じ得る又は生じた事
故、セキュリティ侵害、プライバシー侵害等による被害の性質・態様等に応じて、関係者と協力
して予防措置及び事後対応（情報共有、停止・復旧、原因解明、再発防止措置等）に取
り組むことが期待される。

また、その実効性を確保するため、開発者、AIサービスプロバイダ及びビジネス利用者等が提
供する情報に基づき、関係者と協力して適切に対応することが期待される。

